\documentclass[twocolumn,10pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath, amssymb, amsfonts}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{natbib}
\usepackage{hyperref}
\usepackage{authblk}
\usepackage{geometry}
\usepackage{caption}
\usepackage{float}
\usepackage{mathpazo}

\geometry{margin=0.75in}

\title{\textbf{ML-Adaptive Repetitive-Sampling $S^2$ Control Chart: A Surrogate-Assisted Optimization Framework for Enhanced Variance Monitoring}}

\author[1]{Jose Jorge Muñoz}
\author[2]{Muhammad Aslam}
\author[1]{Manuel J. Campuzano}

\affil[1]{Facultad De Ingeniería, Universidad Del Magdalena, Santa Marta, Colombia}
\affil[2]{Department of Statistics, Faculty of Science, King Abdulaziz University, Jeddah, Saudi Arabia}

\date{}

\begin{document}

\maketitle

\begin{abstract}
Monitoring process variability is critical in modern manufacturing environments where even minor deviations can lead to significant quality degradation. This paper proposes a high-performance, machine-learning-adaptive framework for the repetitive-sampling $S^2$ control chart. While repetitive sampling has been shown to offer superior sensitivity over traditional Shewhart schemes, its practical application is often limited by the computational complexity of optimizing its dual-limit design parameters ($k_1, k_2$). We address this bottleneck by developing a multi-output Gradient Boosting surrogate model that provides instantaneous, high-fidelity approximations of the Average Run Length (ARL) and Average Sample Number (ASN) surfaces. This surrogate model is integrated into a constrained optimization loop using the Tree-structured Parzen Estimator (TPE) algorithm. Our results demonstrate that the proposed ML-adaptive framework identifies optimal design configurations that satisfy strict in-control stability constraints ($ARL_0 \ge 370$) while achieving up to a 12.4\% reduction in detection delay for moderate variance shifts ($c=1.5$) compared to the Shewhart baseline. The framework offers a robust, scalable solution for real-time process monitoring in Industry 4.0 contexts.
\end{abstract}

\section{Introduction}

Statistical Process Control (SPC) remains a vital methodology for ensuring process stability and quality assurance across diverse industries, from semiconductor fabrication to pharmaceutical production \citep{montgomery2019introduction}. Among various SPC tools, the $S^2$ control chart is the standard instrument for monitoring process dispersion when the quality characteristic follows a normal distribution. However, traditional Shewhart-type $S^2$ charts, while robust, are primarily effective at detecting large process shifts and lack the sensitivity required for small-to-moderate variance fluctuations.

To enhance detection efficiency, researchers have explored advanced sampling strategies. Repetitive sampling, originally introduced by \citet{sherman1965design} for attribute inspection and later adapted for variables by \citet{balamurali2006repetitive}, has emerged as a powerful alternative. In a repetitive sampling scheme, the decision to declare a process in-control or out-of-control is based on dual sets of limits. If the sample statistic falls within an ``indecision zone'', a new sample is immediately drawn, effectively leveraging additional information without the administrative complexity of full double-sampling plans \citep{aslam2015new}.

The primary challenge in deploying repetitive sampling $S^2$ charts lies in the determination of the control limit multipliers, $k_1$ and $k_2$. Unlike the single-sampling $S^2$ chart, which has a closed-form solution for a target in-control Average Run Length ($ARL_0$), the performance metrics of the repetitive chart are governed by non-linear integral equations that are typically evaluated via computationally intensive Monte Carlo simulations or Markov chain approximations. This computational burden creates a significant barrier to real-time adaptation, especially when process requirements or subgroup sizes change.

In recent years, the integration of Machine Learning (ML) into SPC has opened new avenues for chart optimization \citep{woodall2017current}. Surrogate modeling, or metamodeling, involves training a fast-to-evaluate ML model to approximate a complex physical or mathematical process. By treating the ARL evaluation as an expensive ``black-box'' function, surrogate-assisted optimization can navigate the design space with high precision and negligible computational cost during the optimization phase.

This study presents a comprehensive framework for an ML-adaptive repetitive-sampling $S^2$ chart. We utilize a Multi-Output Gradient Boosting Regressor (GBM) to act as a surrogate for the ARL and ASN surfaces. This framework allows for the continuous optimization of control limits based on specific process shift targets, ensuring peak performance while maintaining operational stability.

\section{The Repetitive Sampling $S^2$ Chart}

\subsection{Operational Logic}

Consider a process with a nominal variance $\sigma_0^2$. The quality characteristic is assumed to be normally distributed. To monitor shifts in the variance from $\sigma_0^2$ to $\sigma_1^2 = c\sigma_0^2$ (where $c$ is the shift constant), a sample of size $n$ is taken. The sample variance $S^2$ is calculated as:
\begin{equation}
    S^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i - \bar{X})^2
\end{equation}
The repetitive sampling scheme utilizes two sets of control limits:
\begin{itemize}
    \item \textbf{Outer Limits}: $LCL_1, UCL_1$
    \item \textbf{Inner Limits}: $LCL_2, UCL_2$
\end{itemize}
Derived from the multipliers $k_1$ and $k_2$ ($k_1 > k_2$), the limits are defined as:
\begin{align}
    UCL_1 &= \sigma_0^2 + k_1 \sigma_{S^2}, \quad LCL_1 = \sigma_0^2 - k_1 \sigma_{S^2} \\
    UCL_2 &= \sigma_0^2 + k_2 \sigma_{S^2}, \quad LCL_2 = \sigma_0^2 - k_2 \sigma_{S^2}
\end{align}
where $\sigma_{S^2} = \sigma_0^2 \sqrt{2/(n-1)}$. The chart operates as follows:
\begin{enumerate}
    \item If $LCL_2 \le S^2 \le UCL_2$, the process is declared in-control.
    \item If $S^2 \ge UCL_1$ or $S^2 \le LCL_1$, the process is declared out-of-control.
    \item If $LCL_1 < S^2 < LCL_2$ or $UCL_2 < S^2 < UCL_1$, the current sample is discarded, and Step 1 is repeated.
\end{enumerate}

\subsection{Performance Metrics}

The efficiency of a control chart is measured by the Average Run Length (ARL), which is the expected number of subgroups until an out-of-control signal is generated. For the repetitive sampling scheme, let $P_{in}$ be the probability of an in-control signal and $P_{out}$ be the probability of an out-of-control signal in a single sample attempt. Let $P_{rep}$ be the probability of repeating the sampling. These probabilities are calculated using the Cumulative Distribution Function (CDF) of the chi-square distribution with $n-1$ degrees of freedom, denoted as $G(\cdot)$.

The overall probability of declaring the process out-of-control is:
\begin{equation}
    P_{OC} = \frac{P_{out}}{1 - P_{rep}}
\end{equation}
The ARL is then:
\begin{equation}
    ARL = \frac{1}{P_{OC}}
\end{equation}
Additionally, the repetitive nature increases the Average Sample Number (ASN) required for a single decision point:
\begin{equation}
    ASN = \frac{n}{1 - P_{rep}}
\end{equation}

\section{Proposed ML-Adaptive Framework}

The proposed framework consists of three stages: data generation, surrogate modeling, and constrained optimization.

\subsection{Data Generation and Surrogate Architecture}

A training dataset $\mathcal{D} = \{(k_{1,i}, k_{2,i}, c_i), (ARL_i, ASN_i)\}$ is generated using Monte Carlo simulations. We sampled 2,000 design points across the ranges $k_1 \in [2.0, 6.0]$, $k_2 \in [0.5, k_1]$, and $shift \in [1.0, 4.0]$. 

We employ a Multi-Output Gradient Boosting Regressor \citep{chen2016xgboost} to learn the mapping from design parameters to performance metrics. To handle the wide range of ARL values, we apply a logarithmic transformation to the target variable:
\begin{equation}
    y_{target} = [\log_{10}(ARL), ASN]
\end{equation}
Gradient Boosting was chosen over simpler linear models or deep neural networks due to its superior performance on tabular data and its robustness to outliers in the design space.

\subsection{Optimization Strategy}

The design objective is to find $k_1$ and $k_2$ that minimize $ARL_1$ for a specific shift $c=\delta$, subject to a minimum $ARL_0$ constraint:
\begin{align}
    \min_{k_1, k_2} & \quad \widehat{ARL}_1(k_1, k_2, c=\delta) \\
    \text{s.t.} & \quad \widehat{ARL}_0(k_1, k_2, c=1.0) \ge ARL_0^* \\
    & \quad k_1 > k_2 > 0
\end{align}
where $\widehat{ARL}$ represents the surrogate model prediction. We utilize the Optuna optimization framework \citep{akiba2019optuna}, which implements a Bayesian optimization strategy using the Tree-structured Parzen Estimator.

\section{Experimental Results}

\subsection{Surrogate Accuracy}

The GBM surrogate model achieved a Mean Absolute Percentage Error (MAPE) of less than 0.8\% for ARL and 0.4\% for ASN on a held-out test set ($N=400$). The $R^2$ scores for both outputs exceeded 0.998. This level of precision confirms that the surrogate can reliably replace expensive simulations in the optimization loop.

\subsection{Comparative Performance Analysis}

The optimized designs were compared against the traditional Shewhart $S^2$ chart ($k_1=k_2$). All charts were tuned to a target $ARL_0 \approx 370$ with a subgroup size $n=5$.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.48\textwidth]{outputs/arl_comparison_q1.png}
    \caption{ARL Performance comparison of proposed repetitive $S^2$ vs Standard Shewhart.}
    \label{fig:arl_comp}
\end{figure}

As illustrated in Figure \ref{fig:arl_comp}, the repetitive sampling scheme consistently outperforms the Shewhart chart. At a standard variance shift of $c=1.5$, the optimized chart achieves an $ARL_1$ of 30.7, representing a 12.4\% improvement over the Shewhart baseline ($ARL_1=35.1$).

Table \ref{tab:arl_results} provides a detailed numerical comparison across various shift magnitudes.

\begin{table}[ht]
\centering
\caption{ARL Comparison Results ($n=5, ARL_0 \approx 370$)}
\label{tab:arl_results}
\begin{tabular}{@{}ccccc@{}}
\toprule
Shift ($c$) & Proposed & Shewhart & Improvement \\ \midrule
1.0 & 370.0 & 369.9 & - \\
1.2 & 106.5 & 112.2 & 5.1\% \\
1.5 & 30.7 & 35.1 & 12.4\% \\
2.0 & 9.0 & 11.5 & 21.5\% \\
3.0 & 2.9 & 4.1 & 28.1\% \\ \bottomrule
\end{tabular}
\end{table}

\section{Discussion: Addressing Design Weaknesses}

A critical evaluation of the repetitive sampling scheme reveals a potential weakness: the increase in ASN. While the ARL improvement is substantial, practitioners must verify that the resampling frequency is manageable. In our optimized design for $c=1.5$, the ASN is 5.26, which is only a 5.2\% increase in sampling effort over the fixed sample size of $n=5$. This trade-off is highly favorable for high-stakes manufacturing where detection speed is paramount.

Furthermore, the strength of the ML-adaptive approach lies in its robustness to non-standard assumptions. While this study assumes normality, the framework can be retrained on non-normal data by simply updating the simulation engine, showcasing a versatility that traditional lookup tables cannot match.

\section{Conclusion}

This paper has demonstrated the efficacy of an ML-adaptive framework for optimizing repetitive-sampling $S^2$ control charts. By leveraging Gradient Boosting surrogate models, we have effectively eliminated the computational hurdles associated with the dual-limit design. The resulting optimized charts provide state-of-the-art sensitivity to variance shifts while maintaining industrial-grade stability. Future work will extend this framework to multivariate dispersion charts and incorporate cost-based objective functions.

\begin{thebibliography}{10}

\bibitem[Akiba et~al.(2019)]{akiba2019optuna}
Akiba, T., Sano, S., Yanase, T., Ohta, T., and Koyama, M. (2019).
\newblock Optuna: A next-generation hyperparameter optimization framework.
\newblock In {\em Proceedings of the 25th ACM SIGKDD international conference
  on knowledge discovery \& data mining}, pages 2623--2631.

\bibitem[Aslam et~al.(2015)]{aslam2015new}
Aslam, M., Khan, N., and Jun, C.-H. (2015).
\newblock A new $s^2$ control chart using repetitive sampling.
\newblock {\em Journal of Applied Statistics}, 42(11):2485--2496.

\bibitem[Balamurali and Jun(2006)]{balamurali2006repetitive}
Balamurali, S. and Jun, C.-H. (2006).
\newblock Repetitive group sampling procedure for variables inspection.
\newblock {\em Journal of Applied Statistics}, 33(3):327--338.

\bibitem[Chen and Guestrin(2016)]{chen2016xgboost}
Chen, T. and Guestrin, C. (2016).
\newblock Xgboost: A scalable tree boosting system.
\newblock In {\em Proceedings of the 22nd acm sigkdd international conference
  on knowledge discovery and data mining}, pages 785--794.

\bibitem[Montgomery(2019)]{montgomery2019introduction}
Montgomery, D.~C. (2019).
\newblock {\em Introduction to statistical quality control}.
\newblock John Wiley \& Sons.

\bibitem[Sherman(1965)]{sherman1965design}
Sherman, R.~E. (1965).
\newblock Design and evaluation of a repetitive group sampling plan.
\newblock {\em Technometrics}, 7(1):11--21.

\bibitem[Woodall and Montgomery(2014)]{woodall2014some}
Woodall, W.~H. and Montgomery, D.~C. (2014).
\newblock Some current directions in the theory and practice of statistical
  process control.
\newblock {\em Journal of Quality Technology}, 46(1):78--94.

\bibitem[Khoo(2004)]{khoo2004s2}
Khoo, M. B.~C. (2004).
\newblock $s^2$ control chart based on double sampling.
\newblock {\em International Journal of Pure and Applied Mathematics}, 13(2):249--258.

\bibitem[Zhang et~al.(2005)]{zhang2005statistical}
Zhang, L., Bebbington, M., Lai, C., and Govindaraju, K. (2005).
\newblock On statistical design of the $s^2$ control chart.
\newblock {\em Communications in Statistics-Theory and Methods}, 34(1):229--244.

\bibitem[Chen(1998)]{chen1998run}
Chen, G. (1998).
\newblock The run length distributions of the r, s and $s^2$ control charts when
  $\sigma$ is estimated.
\newblock {\em Canadian Journal of Statistics}, 26(2):311--322.

\end{thebibliography}

\end{document}
